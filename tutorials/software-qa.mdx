---
title: "Software QA Tutorial"
description: "Build a custom QA agent that clicks through UI elements and validates each screen with a VLM."
icon: "bug"
---

# Software QA Tutorial

Build a custom TaskerAgent that automates UI testing by clicking through every sidebar button in an application and using a Vision Language Model (VLM) to verify each screen. We'll assemble the workflow piece by piece‚Äîextending TaskerAgent with custom validation logic.

## What You'll Build

- A custom `QATaskerAgent` that extends the base TaskerAgent
- Automated clicking through all sidebar navigation items
- VLM-powered screenshot analysis to verify each page loaded correctly
- HTML execution history for debugging and compliance

## Prerequisites

1. **OAGI credentials** ‚Äì Generate an API key at [developer.openagi.org](https://developer.openagi.org/) and export it in your shell:
   ```bash
   export OAGI_API_KEY="sk-your-key"
   export OAGI_BASE_URL="https://api.agiopen.org"
   ```
2. **Python ‚â• 3.10 with desktop extras**:
   ```bash
   pip install "oagi>=0.10.1"
   ```
3. **A VLM for validation** ‚Äì This tutorial uses a custom `ModelEngine` class. You can substitute with any vision model (GPT-4V, Gemini, Claude, etc.).
4. **Nuclear Player** ‚Äì We'll use [Nuclear](https://github.com/nukeop/nuclear), an open-source streaming music player built with Electron. Install and run it locally so the agent can target its UI:
   ```bash
   git clone https://github.com/nukeop/nuclear.git
   cd nuclear
   npm install
   npm start
   ```

## Project Layout

Create a `tutorials/qa` folder with:

- `nuclear_qa.py` ‚Äì main script
- `model_engine.py` ‚Äì your VLM wrapper
- `apis/gemini.json` ‚Äì model configuration
- `results/` ‚Äì destination for screenshots and HTML transcripts

```
tutorials/qa/
‚îú‚îÄ‚îÄ nuclear_qa.py
‚îú‚îÄ‚îÄ model_engine.py
‚îú‚îÄ‚îÄ apis/
‚îÇ   ‚îî‚îÄ‚îÄ gemini.json
‚îî‚îÄ‚îÄ results/
```

## Tutorial Roadmap

We'll assemble the script in seven steps:

1. Bootstrap the project with imports
2. Create a screenshot analysis helper
3. Extend TaskerAgent with custom QA logic
4. Define the QA workflow as todos
5. Initialize and configure the agent
6. Execute and collect QA results
7. Export the execution history

### Step 1 ‚Äî Bootstrap the project

Start with the imports you'll need:

```python
import os
import json
import argparse
import base64
import asyncio
import traceback
from datetime import datetime
import logging

from oagi import AsyncScreenshotMaker
from oagi.types import SplitEvent
from oagi.agent.observer import AsyncAgentObserver
from oagi.agent.tasker import TaskerAgent
from oagi.handler import AsyncPyautoguiActionHandler

# Your custom VLM wrapper
from model_engine import ModelEngine, ModelInfo

logger = logging.getLogger(__name__)


async def main():
    print("Bootstrapping QA Tasker‚Ä¶")


if __name__ == "__main__":
    asyncio.run(main())
```

### Step 2 ‚Äî Create a screenshot analysis helper

This function encodes a screenshot and asks the VLM to answer a question about it:

```python
def analyze_screenshot(screenshot_path: str, question: str, vlm: ModelEngine):
    """Encode a screenshot and ask the model to answer `question` about it."""
    if not os.path.exists(screenshot_path):
        raise FileNotFoundError(f"Screenshot not found: {screenshot_path}")

    with open(screenshot_path, "rb") as f:
        b64_image = base64.b64encode(f.read()).decode("ascii")

    lower_path = screenshot_path.lower()
    if lower_path.endswith((".jpg", ".jpeg")):
        mime = "image/jpeg"
    else:
        mime = "image/png"

    user_messages = [
        {"type": "text", "content": question},
        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64_image}"}},
    ]

    return vlm([], user_messages)
```

This helper handles image encoding and MIME type detection, making it easy to query the VLM about any screenshot.

### Step 3 ‚Äî Extend TaskerAgent with QA logic

Create a custom `QATaskerAgent` that validates each todo completion with the VLM:

```python
class QATaskerAgent(TaskerAgent):
    def __init__(self, list_of_checkers: list[str], vlm: ModelEngine, save_dir: str, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.list_of_checkers = list_of_checkers
        self.vlm = vlm
        self.save_dir = save_dir
        self.qa_result = {}
    
    async def execute(
        self,
        instruction: str,
        action_handler: AsyncPyautoguiActionHandler,
        image_provider: AsyncScreenshotMaker,
    ):
        overall_success = True

        while True:
            todo_info = self._prepare()

            if todo_info is None:
                logger.info("No more todos to execute")
                break

            todo, todo_index = todo_info
            logger.info(f"Executing todo {todo_index}: {todo.description}")

            # Emit split event at the start of todo
            if self.step_observer:
                await self.step_observer.on_event(
                    SplitEvent(label=f"Start of todo {todo_index + 1}: {todo.description}")
                )

            # Execute the todo
            success = await self._execute_todo(todo_index, action_handler, image_provider)

            # Emit split event after each todo
            if self.step_observer:
                await self.step_observer.on_event(
                    SplitEvent(label=f"End of todo {todo_index + 1}: {todo.description}")
                )

            if not success:
                logger.warning(f"Todo {todo_index} failed")
                overall_success = False
                break

            self._update_task_summary()

            # Validate with VLM
            screenshot_path = os.path.join(
                self.save_dir, 
                f"todo_{todo_index}_{self.list_of_checkers[todo_index]}_screenshot.png"
            )
            last_screenshot = await image_provider()
            last_screenshot.image.save(screenshot_path)
            
            result = analyze_screenshot(
                screenshot_path, 
                f"Check if software is displaying the page of {self.list_of_checkers[todo_index]} with a simple yes or no answer", 
                self.vlm
            )
            print(f"VLM result for {self.list_of_checkers[todo_index]}: {result}")
            self.qa_result[self.list_of_checkers[todo_index]] = result

        status_summary = self.memory.get_todo_status_summary()
        logger.info(f"Workflow complete. Status summary: {status_summary}")

        return overall_success, self.qa_result
```

The key addition is the VLM validation after each todo‚Äîthe agent takes a screenshot and asks the VLM to confirm the expected page is displayed.

### Step 4 ‚Äî Define the QA workflow

Define todos for each UI element you want to test, along with corresponding checkers:

```python
    instruction = "QA: click through every sidebar button in the Nuclear Player UI"
    todos = [
        "Click on 'Dashboard' in the left sidebar",
        "Click on 'Downloads' in the left sidebar",
        "Click on 'Lyrics' in the left sidebar",
        "Click on 'Plugins' in the left sidebar",
        "Click on 'Search Results' in the left sidebar",
        "Click on 'Settings' in the left sidebar",
        "Click on 'Equalizer' in the left sidebar",
        "Click on 'Visualizer' in the left sidebar",
        "Click on 'Listening History' in the left sidebar",
        "Click on 'Favorite Albums' in the left sidebar",
        "Click on 'Favorite Tracks' in the left sidebar",
        "Click on 'Favorite Artists' in the left sidebar",
        "Click on 'Local Library' in the left sidebar",
        "Click on 'Playlists' in the left sidebar",
    ]

    list_of_checkers = [
        "Dashboard", "Downloads", "Lyrics", "Plugins",
        "Search Results", "Settings", "Equalizer", "Visualizer",
        "Listening History", "Favorite Albums", "Favorite Tracks",
        "Favorite Artists", "Local Library", "Playlists",
    ]
```

Each todo maps to a checker that the VLM will use to validate the screen.

### Step 5 ‚Äî Initialize and configure the agent

Set up argument parsing and initialize all components:

```python
    parser = argparse.ArgumentParser(description='Run QA Agent on Nuclear Player')
    parser.add_argument('--exp_name', type=str, default='nuclear_qa')
    parser.add_argument('--model_info_path', type=str, default='apis/gemini.json')
    parser.add_argument('--save_dir', type=str, default='results/')
    parser.add_argument('--product_name', type=str, default='nuclear_player')
    parser.add_argument('--model_name', type=str, default='lux-actor-1')
    parser.add_argument('--max_steps', type=int, default=24)
    parser.add_argument('--temperature', type=float, default=0.0)

    args = parser.parse_args()

    save_dir = os.path.join(args.save_dir, args.exp_name)
    os.makedirs(save_dir, exist_ok=True)

    # Load VLM
    with open(args.model_info_path, 'r', encoding='utf-8') as f:
        model_info = json.load(f)
    model_info = ModelInfo(**model_info)
    vlm = ModelEngine(model_info)

    # Initialize automation toolkit
    observer = AsyncAgentObserver()
    image_provider = AsyncScreenshotMaker()
    action_handler = AsyncPyautoguiActionHandler()

    tasker = QATaskerAgent(
        api_key=os.getenv("OAGI_API_KEY"),
        base_url=os.getenv("OAGI_BASE_URL", "https://api.agiopen.org"),
        model=args.model_name,
        max_steps=args.max_steps,
        temperature=args.temperature,
        step_observer=observer,
        list_of_checkers=list_of_checkers,
        vlm=vlm,
        save_dir=save_dir,
    )

    tasker.set_task(task=instruction, todos=todos)
```

### Step 6 ‚Äî Execute and collect results

Run the agent and display detailed results:

```python
    print(f"Starting task execution at {datetime.now()}")
    print(f"Task: {instruction}")
    print(f"Number of todos: {len(todos)}")
    print("=" * 60)

    try:
        success, qa_result = await tasker.execute(
            instruction="",
            action_handler=action_handler,
            image_provider=image_provider,
        )

        memory = tasker.get_memory()

        print("\n" + "=" * 60)
        print("EXECUTION SUMMARY")
        print("=" * 60)
        print(f"Overall success: {success}")
        print(f"\nTask execution summary:\n{memory.task_execution_summary}")

        # Print todo statuses
        print("\nTodo Status:")
        for i, todo in enumerate(memory.todos):
            status_icon = {
                "completed": "‚úÖ",
                "pending": "‚è≥",
                "in_progress": "üîÑ",
                "skipped": "‚è≠Ô∏è",
            }.get(todo.status.value, "‚ùì")
            print(f"  {status_icon} [{i + 1}] {todo.description} - {todo.status.value}")

        # Print execution statistics
        status_summary = memory.get_todo_status_summary()
        print("\nExecution Statistics:")
        print(f"  Completed: {status_summary.get('completed', 0)}")
        print(f"  Pending: {status_summary.get('pending', 0)}")
        print(f"  In Progress: {status_summary.get('in_progress', 0)}")
        print(f"  Skipped: {status_summary.get('skipped', 0)}")

        # Print QA results
        print("\nQA Validation Results:")
        for checker, result in qa_result.items():
            print(f"  {checker}: {result}")

    except Exception as e:
        print(f"\n‚ùå Error during execution: {e}")
        traceback.print_exc()
```

### Step 7 ‚Äî Export the execution history

Save artifacts for debugging and compliance:

```python
    # Final screenshot analysis
    screenshot_path = os.path.join(save_dir, f"{args.product_name}_screenshot.png")
    last_screenshot = await image_provider()
    last_screenshot.image.save(screenshot_path)
    result = analyze_screenshot(
        screenshot_path,
        "List the sidebar buttons visible in the Nuclear Player and describe any that look disabled.",
        vlm,
    )
    print(f"VLM result: {result}")

    # Export HTML history
    output_file = os.path.join(save_dir, "nuclear_qa_execution_history.html")
    observer.export("html", output_file)
    print(f"\nüìÑ Execution history exported to: {output_file}")
```

## Run the Workflow

Launch the QA automation (make sure Nuclear Player is open and visible):

```bash
python nuclear_qa.py \
  --exp_name="nuclear_qa" \
  --model_name="lux-actor-1" \
  --max_steps=24
```

## Understanding the Output

- **Console summary** ‚Äì Displays per-todo success with emoji indicators and VLM validation results
- **QA results** ‚Äì Shows whether each page was correctly identified by the VLM
- **HTML export** ‚Äì Stored under `results/<exp_name>/nuclear_qa_execution_history.html` with screenshots for every step

## Full Source Listing

Here is the complete script assembled from the steps above:

```python
import os
import json
import argparse
import base64
import asyncio
import traceback
from datetime import datetime
import logging

from oagi import AsyncScreenshotMaker
from oagi.types import SplitEvent
from oagi.agent.observer import AsyncAgentObserver
from oagi.agent.tasker import TaskerAgent
from oagi.handler import AsyncPyautoguiActionHandler

from model_engine import ModelEngine, ModelInfo

logger = logging.getLogger(__name__)


def analyze_screenshot(screenshot_path: str, question: str, vlm: ModelEngine):
    """Encode a screenshot and ask the model to answer `question` about it."""
    if not os.path.exists(screenshot_path):
        raise FileNotFoundError(f"Screenshot not found: {screenshot_path}")

    with open(screenshot_path, "rb") as f:
        b64_image = base64.b64encode(f.read()).decode("ascii")

    lower_path = screenshot_path.lower()
    if lower_path.endswith((".jpg", ".jpeg")):
        mime = "image/jpeg"
    else:
        mime = "image/png"

    user_messages = [
        {"type": "text", "content": question},
        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64_image}"}},
    ]

    return vlm([], user_messages)


class QATaskerAgent(TaskerAgent):
    def __init__(self, list_of_checkers: list[str], vlm: ModelEngine, save_dir: str, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.list_of_checkers = list_of_checkers
        self.vlm = vlm
        self.save_dir = save_dir
        self.qa_result = {}
    
    async def execute(
        self,
        instruction: str,
        action_handler: AsyncPyautoguiActionHandler,
        image_provider: AsyncScreenshotMaker,
    ):
        overall_success = True

        while True:
            todo_info = self._prepare()

            if todo_info is None:
                logger.info("No more todos to execute")
                break

            todo, todo_index = todo_info
            logger.info(f"Executing todo {todo_index}: {todo.description}")

            if self.step_observer:
                await self.step_observer.on_event(
                    SplitEvent(label=f"Start of todo {todo_index + 1}: {todo.description}")
                )

            success = await self._execute_todo(todo_index, action_handler, image_provider)

            if self.step_observer:
                await self.step_observer.on_event(
                    SplitEvent(label=f"End of todo {todo_index + 1}: {todo.description}")
                )

            if not success:
                logger.warning(f"Todo {todo_index} failed")
                overall_success = False
                break

            self._update_task_summary()

            screenshot_path = os.path.join(
                self.save_dir, 
                f"todo_{todo_index}_{self.list_of_checkers[todo_index]}_screenshot.png"
            )
            last_screenshot = await image_provider()
            last_screenshot.image.save(screenshot_path)
            
            result = analyze_screenshot(
                screenshot_path, 
                f"Check if software is displaying the page of {self.list_of_checkers[todo_index]} with a simple yes or no answer", 
                self.vlm
            )
            print(f"VLM result for {self.list_of_checkers[todo_index]}: {result}")
            self.qa_result[self.list_of_checkers[todo_index]] = result

        status_summary = self.memory.get_todo_status_summary()
        logger.info(f"Workflow complete. Status summary: {status_summary}")

        return overall_success, self.qa_result


async def main():
    parser = argparse.ArgumentParser(description='Run QA Agent on Nuclear Player')
    parser.add_argument('--exp_name', type=str, default='nuclear_qa')
    parser.add_argument('--model_info_path', type=str, default='apis/gemini.json')
    parser.add_argument('--save_dir', type=str, default='results/')
    parser.add_argument('--product_name', type=str, default='nuclear_player')
    parser.add_argument('--model_name', type=str, default='lux-actor-1')
    parser.add_argument('--max_steps', type=int, default=24)
    parser.add_argument('--temperature', type=float, default=0.0)

    args = parser.parse_args()

    save_dir = os.path.join(args.save_dir, args.exp_name)
    os.makedirs(save_dir, exist_ok=True)

    with open(args.model_info_path, 'r', encoding='utf-8') as f:
        model_info = json.load(f)
    model_info = ModelInfo(**model_info)
    vlm = ModelEngine(model_info)

    instruction = "QA: click through every sidebar button in the Nuclear Player UI"
    todos = [
        "Click on 'Dashboard' in the left sidebar",
        "Click on 'Downloads' in the left sidebar",
        "Click on 'Lyrics' in the left sidebar",
        "Click on 'Plugins' in the left sidebar",
        "Click on 'Search Results' in the left sidebar",
        "Click on 'Settings' in the left sidebar",
        "Click on 'Equalizer' in the left sidebar",
        "Click on 'Visualizer' in the left sidebar",
        "Click on 'Listening History' in the left sidebar",
        "Click on 'Favorite Albums' in the left sidebar",
        "Click on 'Favorite Tracks' in the left sidebar",
        "Click on 'Favorite Artists' in the left sidebar",
        "Click on 'Local Library' in the left sidebar",
        "Click on 'Playlists' in the left sidebar",
    ]

    list_of_checkers = [
        "Dashboard", "Downloads", "Lyrics", "Plugins",
        "Search Results", "Settings", "Equalizer", "Visualizer",
        "Listening History", "Favorite Albums", "Favorite Tracks",
        "Favorite Artists", "Local Library", "Playlists",
    ]

    observer = AsyncAgentObserver()
    image_provider = AsyncScreenshotMaker()
    action_handler = AsyncPyautoguiActionHandler()

    tasker = QATaskerAgent(
        api_key=os.getenv("OAGI_API_KEY"),
        base_url=os.getenv("OAGI_BASE_URL", "https://api.agiopen.org"),
        model=args.model_name,
        max_steps=args.max_steps,
        temperature=args.temperature,
        step_observer=observer,
        list_of_checkers=list_of_checkers,
        vlm=vlm,
        save_dir=save_dir,
    )

    tasker.set_task(task=instruction, todos=todos)

    print(f"Starting task execution at {datetime.now()}")
    print(f"Task: {instruction}")
    print(f"Number of todos: {len(todos)}")
    print("=" * 60)

    try:
        success, qa_result = await tasker.execute(
            instruction="",
            action_handler=action_handler,
            image_provider=image_provider,
        )

        memory = tasker.get_memory()

        print("\n" + "=" * 60)
        print("EXECUTION SUMMARY")
        print("=" * 60)
        print(f"Overall success: {success}")
        print(f"\nTask execution summary:\n{memory.task_execution_summary}")

        print("\nTodo Status:")
        for i, todo in enumerate(memory.todos):
            status_icon = {
                "completed": "‚úÖ",
                "pending": "‚è≥",
                "in_progress": "üîÑ",
                "skipped": "‚è≠Ô∏è",
            }.get(todo.status.value, "‚ùì")
            print(f"  {status_icon} [{i + 1}] {todo.description} - {todo.status.value}")

        status_summary = memory.get_todo_status_summary()
        print("\nExecution Statistics:")
        print(f"  Completed: {status_summary.get('completed', 0)}")
        print(f"  Pending: {status_summary.get('pending', 0)}")
        print(f"  In Progress: {status_summary.get('in_progress', 0)}")
        print(f"  Skipped: {status_summary.get('skipped', 0)}")

        print("\nQA Validation Results:")
        for checker, result in qa_result.items():
            print(f"  {checker}: {result}")

    except Exception as e:
        print(f"\n‚ùå Error during execution: {e}")
        traceback.print_exc()

    screenshot_path = os.path.join(save_dir, f"{args.product_name}_screenshot.png")
    last_screenshot = await image_provider()
    last_screenshot.image.save(screenshot_path)
    result = analyze_screenshot(
        screenshot_path,
        "List the sidebar buttons visible in the Nuclear Player and describe any that look disabled.",
        vlm,
    )
    print(f"VLM result: {result}")

    output_file = os.path.join(save_dir, "nuclear_qa_execution_history.html")
    observer.export("html", output_file)
    print(f"\nüìÑ Execution history exported to: {output_file}")


if __name__ == '__main__':
    asyncio.run(main())
```

## Adapting for Your Application

To use this pattern with a different application:

1. **Update the todos** ‚Äì Replace sidebar button names with your app's UI elements
2. **Update the checkers** ‚Äì Match each todo with the expected page/state name
3. **Adjust VLM prompts** ‚Äì Customize the validation questions for your UI

This pattern works for any desktop application with navigable UI elements‚Äîsettings panels, menu systems, wizard flows, etc.

## Troubleshooting

| Symptom | Likely cause | Fix |
| --- | --- | --- |
| VLM returns incorrect validation | Screenshot quality or timing | Add delays between actions or improve VLM prompt specificity |
| Agent clicks wrong element | Ambiguous UI or overlapping elements | Make todo instructions more specific (e.g., "in the left sidebar") |
| `FileNotFoundError` for model config | Missing `apis/gemini.json` | Create the config file with your VLM credentials |

With this workflow you now have a reusable QA automation pattern that combines OAGI's desktop control with VLM-powered visual validation.

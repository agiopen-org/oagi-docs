---
title: "Amazon Data Crawling"
description: "Use the OAGI Python SDK's TaskerAgent to crawl Amazon product pages and extract data."
icon: "amazon"
---

# Amazon Data Crawling Tutorial

Build a TaskerAgent that automates product research on Amazon‚Äînavigating to the site, searching for products, sorting by best sellers, and using a Vision Language Model (VLM) to extract structured product data from the results.

## What You'll Build

- Automated browser navigation to Amazon
- Product search and sorting by best sellers
- VLM-powered screenshot analysis to extract product details (name, color, price, discount)
- JSON export of extracted data
- HTML execution history for debugging

## Prerequisites

1. **OAGI credentials** ‚Äì Generate an API key at [developer.openagi.org](https://developer.openagi.org/) and export it in your shell:
   ```bash
   export OAGI_API_KEY=sk-your-key
   export OAGI_BASE_URL=https://api.agiopen.org
   ```
2. **Python ‚â• 3.10 with desktop extras**:
   ```bash
   pip install "oagi>=0.10.1"
   ```
3. **A VLM for data extraction** ‚Äì This tutorial uses a custom `ModelEngine` class. You can substitute with any vision model (GPT-4V, Gemini, Claude, etc.).
4. **A web browser** ‚Äì The agent will open new tabs and navigate to Amazon.

## Project Layout

Create a `tutorials/amazon` folder with:

- `amazon_crawler.py` ‚Äì main script
- `model_engine.py` ‚Äì your VLM wrapper
- `apis/gemini.json` ‚Äì model configuration
- `results/` ‚Äì destination for screenshots, JSON data, and HTML transcripts

```
tutorials/amazon/
‚îú‚îÄ‚îÄ amazon_crawler.py
‚îú‚îÄ‚îÄ model_engine.py
‚îú‚îÄ‚îÄ apis/
‚îÇ   ‚îî‚îÄ‚îÄ gemini.json
‚îî‚îÄ‚îÄ results/
```

## Tutorial Roadmap

We'll assemble the script in six steps:

1. Bootstrap the project with imports
2. Create a screenshot analysis helper
3. Define the crawling workflow
4. Initialize and configure the agent
5. Execute and extract product data
6. Export results and execution history

### Step 1 ‚Äî Bootstrap the project

Start with the imports you'll need:

```python
import os
import json
import argparse
import base64
import asyncio
import traceback
from datetime import datetime

from oagi import AsyncScreenshotMaker
from oagi.agent.observer import AsyncAgentObserver
from oagi.agent.tasker import TaskerAgent
from oagi.handler import AsyncPyautoguiActionHandler

# Your custom VLM wrapper
from model_engine import ModelEngine, ModelInfo


async def main():
    print("Bootstrapping Amazon Crawler‚Ä¶")


if __name__ == "__main__":
    asyncio.run(main())
```

### Step 2 ‚Äî Create a screenshot analysis helper

This function encodes a screenshot and asks the VLM to extract product information:

```python
def analyze_screenshot(screenshot_path: str, question: str, vlm: ModelEngine):
    """Encode a screenshot and ask the model to answer `question` about it."""
    if not os.path.exists(screenshot_path):
        raise FileNotFoundError(f"Screenshot not found: {screenshot_path}")

    with open(screenshot_path, "rb") as f:
        b64_image = base64.b64encode(f.read()).decode("ascii")

    lower_path = screenshot_path.lower()
    if lower_path.endswith((".jpg", ".jpeg")):
        mime = "image/jpeg"
    else:
        mime = "image/png"

    user_messages = [
        {"type": "text", "content": question},
        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64_image}"}},
    ]

    return vlm([], user_messages)
```

This helper handles image encoding and MIME type detection, making it easy to query the VLM about any screenshot.

### Step 3 ‚Äî Define the crawling workflow

Define the instruction and todos for the Amazon crawling task:

```python
    product_name = args.product_name  # e.g., "purse"

    instruction = f"Find the information about the top-selling {product_name} on Amazon"
    todos = [
        f"Open a new tab, go to www.amazon.com, and search for {product_name} in the search bar",
        f"Click on 'Sort by' in the top right of the page and select 'Best Sellers'",
    ]
```

**Key tip:** When writing todos, be specific about UI element locations. For example, "in the top right of the page" helps the agent locate the correct element.

### Step 4 ‚Äî Initialize and configure the agent

Set up argument parsing and initialize all components:

```python
    parser = argparse.ArgumentParser(description='Crawl Amazon for product data')
    parser.add_argument('--product_name', type=str, default='purse', help='Product name to search for')
    parser.add_argument('--exp_name', type=str, default='amazon_crawl', help='Experiment name')
    parser.add_argument('--model_info_path', type=str, default='apis/gemini.json', help='Path to model info JSON')
    parser.add_argument('--save_dir', type=str, default='results/', help='Directory to save results')
    parser.add_argument('--model_name', type=str, default='lux-actor-1', help='Model name')
    parser.add_argument('--max_steps', type=int, default=24, help='Max steps per todo')
    parser.add_argument('--temperature', type=float, default=0.0, help='Temperature')

    args = parser.parse_args()

    save_dir = os.path.join(args.save_dir, args.exp_name)
    os.makedirs(save_dir, exist_ok=True)

    # Load VLM
    with open(args.model_info_path, 'r', encoding='utf-8') as f:
        model_info = json.load(f)
    model_info = ModelInfo(**model_info)
    vlm = ModelEngine(model_info)

    # Initialize automation toolkit
    observer = AsyncAgentObserver()
    image_provider = AsyncScreenshotMaker()
    action_handler = AsyncPyautoguiActionHandler()

    tasker = TaskerAgent(
        api_key=os.getenv("OAGI_API_KEY"),
        base_url=os.getenv("OAGI_BASE_URL", "https://api.agiopen.org"),
        model=args.model_name,
        max_steps=args.max_steps,
        temperature=args.temperature,
        step_observer=observer,
    )

    tasker.set_task(task=instruction, todos=todos)
```

### Step 5 ‚Äî Execute and extract product data

Run the agent and use the VLM to extract structured data from the results:

```python
    print(f"Starting task execution at {datetime.now()}")
    print(f"Task: {instruction}")
    print(f"Number of todos: {len(todos)}")
    print("=" * 60)

    try:
        success = await tasker.execute(
            instruction="",
            action_handler=action_handler,
            image_provider=image_provider,
        )

        memory = tasker.get_memory()

        print("\n" + "=" * 60)
        print("EXECUTION SUMMARY")
        print("=" * 60)
        print(f"Overall success: {success}")
        print(f"\nTask execution summary:\n{memory.task_execution_summary}")

        # Print todo statuses
        print("\nTodo Status:")
        for i, todo in enumerate(memory.todos):
            status_icon = {
                "completed": "‚úÖ",
                "pending": "‚è≥",
                "in_progress": "üîÑ",
                "skipped": "‚è≠Ô∏è",
            }.get(todo.status.value, "‚ùì")
            print(f"  {status_icon} [{i + 1}] {todo.description} - {todo.status.value}")

        # Print execution statistics
        status_summary = memory.get_todo_status_summary()
        print("\nExecution Statistics:")
        print(f"  Completed: {status_summary.get('completed', 0)}")
        print(f"  Pending: {status_summary.get('pending', 0)}")
        print(f"  In Progress: {status_summary.get('in_progress', 0)}")
        print(f"  Skipped: {status_summary.get('skipped', 0)}")

    except Exception as e:
        print(f"\n‚ùå Error during execution: {e}")
        traceback.print_exc()

    # Analyze the final screenshot with VLM
    screenshot_path = os.path.join(save_dir, f"{args.product_name}_screenshot.png")
    last_screenshot = await image_provider()
    last_screenshot.image.save(screenshot_path)
    
    result = analyze_screenshot(
        screenshot_path,
        "Describe the name, color, price, and discount of the items in the first row of the search results",
        vlm,
    )
    print(f"VLM result: {result}")
```

### Step 6 ‚Äî Export results and execution history

Save the extracted data and execution artifacts:

```python
    # Save JSON results
    result_path = os.path.join(save_dir, f"{args.product_name}_result.json")
    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump({
            "result": result,
            "screenshot_path": screenshot_path,
        }, f, ensure_ascii=False, indent=4)
    print(f"Results saved to {result_path}")

    # Export HTML execution history
    output_file = os.path.join(save_dir, f"{args.product_name}_execution_history.html")
    observer.export("html", output_file)
    print(f"\nüìÑ Execution history exported to: {output_file}")
```

## Run the Workflow

Launch the Amazon crawler:

```bash
python amazon_crawler.py \
  --product_name="headphones" \
  --exp_name="amazon_crawl" \
  --model_name="lux-actor-1"
```

## Understanding the Output

- **Console summary** ‚Äì Displays per-todo success with emoji indicators
- **JSON export** ‚Äì Stored under `results/<exp_name>/<product_name>_result.json` with extracted product data
- **Screenshot** ‚Äì The final page screenshot saved for reference
- **HTML export** ‚Äì Full execution history with screenshots at `results/<exp_name>/<product_name>_execution_history.html`

## Full Source Listing

Here is the complete script assembled from the steps above:

```python
import os
import json
import argparse
import base64
import asyncio
import traceback
from datetime import datetime

from oagi import AsyncScreenshotMaker
from oagi.agent.observer import AsyncAgentObserver
from oagi.agent.tasker import TaskerAgent
from oagi.handler import AsyncPyautoguiActionHandler

from model_engine import ModelEngine, ModelInfo


def analyze_screenshot(screenshot_path: str, question: str, vlm: ModelEngine):
    """Encode a screenshot and ask the model to answer `question` about it."""
    if not os.path.exists(screenshot_path):
        raise FileNotFoundError(f"Screenshot not found: {screenshot_path}")

    with open(screenshot_path, "rb") as f:
        b64_image = base64.b64encode(f.read()).decode("ascii")

    lower_path = screenshot_path.lower()
    if lower_path.endswith((".jpg", ".jpeg")):
        mime = "image/jpeg"
    else:
        mime = "image/png"

    user_messages = [
        {"type": "text", "content": question},
        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64_image}"}},
    ]

    return vlm([], user_messages)


async def main():
    parser = argparse.ArgumentParser(description='Crawl Amazon for product data')
    parser.add_argument('--product_name', type=str, default='purse', help='Product name to search for')
    parser.add_argument('--exp_name', type=str, default='amazon_crawl', help='Experiment name')
    parser.add_argument('--model_info_path', type=str, default='apis/gemini.json', help='Path to model info JSON')
    parser.add_argument('--save_dir', type=str, default='results/', help='Directory to save results')
    parser.add_argument('--model_name', type=str, default='lux-actor-1', help='Model name')
    parser.add_argument('--max_steps', type=int, default=24, help='Max steps per todo')
    parser.add_argument('--temperature', type=float, default=0.0, help='Temperature')

    args = parser.parse_args()

    save_dir = os.path.join(args.save_dir, args.exp_name)
    os.makedirs(save_dir, exist_ok=True)

    # Load VLM
    with open(args.model_info_path, 'r', encoding='utf-8') as f:
        model_info = json.load(f)
    model_info = ModelInfo(**model_info)
    vlm = ModelEngine(model_info)

    # Define the workflow
    instruction = f"Find the information about the top-selling {args.product_name} on Amazon"
    todos = [
        f"Open a new tab, go to www.amazon.com, and search for {args.product_name} in the search bar",
        f"Click on 'Sort by' in the top right of the page and select 'Best Sellers'",
    ]

    # Initialize automation toolkit
    observer = AsyncAgentObserver()
    image_provider = AsyncScreenshotMaker()
    action_handler = AsyncPyautoguiActionHandler()

    tasker = TaskerAgent(
        api_key=os.getenv("OAGI_API_KEY"),
        base_url=os.getenv("OAGI_BASE_URL", "https://api.agiopen.org"),
        model=args.model_name,
        max_steps=args.max_steps,
        temperature=args.temperature,
        step_observer=observer,
    )

    tasker.set_task(task=instruction, todos=todos)

    print(f"Starting task execution at {datetime.now()}")
    print(f"Task: {instruction}")
    print(f"Number of todos: {len(todos)}")
    print("=" * 60)

    try:
        success = await tasker.execute(
            instruction="",
            action_handler=action_handler,
            image_provider=image_provider,
        )

        memory = tasker.get_memory()

        print("\n" + "=" * 60)
        print("EXECUTION SUMMARY")
        print("=" * 60)
        print(f"Overall success: {success}")
        print(f"\nTask execution summary:\n{memory.task_execution_summary}")

        print("\nTodo Status:")
        for i, todo in enumerate(memory.todos):
            status_icon = {
                "completed": "‚úÖ",
                "pending": "‚è≥",
                "in_progress": "üîÑ",
                "skipped": "‚è≠Ô∏è",
            }.get(todo.status.value, "‚ùì")
            print(f"  {status_icon} [{i + 1}] {todo.description} - {todo.status.value}")

        status_summary = memory.get_todo_status_summary()
        print("\nExecution Statistics:")
        print(f"  Completed: {status_summary.get('completed', 0)}")
        print(f"  Pending: {status_summary.get('pending', 0)}")
        print(f"  In Progress: {status_summary.get('in_progress', 0)}")
        print(f"  Skipped: {status_summary.get('skipped', 0)}")

    except Exception as e:
        print(f"\n‚ùå Error during execution: {e}")
        traceback.print_exc()

    # Analyze the final screenshot with VLM
    screenshot_path = os.path.join(save_dir, f"{args.product_name}_screenshot.png")
    last_screenshot = await image_provider()
    last_screenshot.image.save(screenshot_path)
    
    result = analyze_screenshot(
        screenshot_path,
        "Describe the name, color, price, and discount of the items in the first row of the search results",
        vlm,
    )
    print(f"VLM result: {result}")

    # Save JSON results
    result_path = os.path.join(save_dir, f"{args.product_name}_result.json")
    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump({
            "result": result,
            "screenshot_path": screenshot_path,
        }, f, ensure_ascii=False, indent=4)
    print(f"Results saved to {result_path}")

    # Export HTML execution history
    output_file = os.path.join(save_dir, f"{args.product_name}_execution_history.html")
    observer.export("html", output_file)
    print(f"\nüìÑ Execution history exported to: {output_file}")


if __name__ == '__main__':
    asyncio.run(main())
```

## Customizing the Workflow

To adapt this for different use cases:

1. **Change the product** ‚Äì Use `--product_name` to search for any product category
2. **Modify todos** ‚Äì Add steps like clicking into a product detail page or adding to cart
3. **Customize VLM prompts** ‚Äì Ask for different data points (ratings, reviews, shipping info)
4. **Add more todos** ‚Äì Paginate through results or compare multiple products

Example with more detailed extraction:

```python
todos = [
    f"Open a new tab, go to www.amazon.com, and search for {product_name} in the search bar",
    f"Click on 'Sort by' in the top right of the page and select 'Best Sellers'",
    "Click on the first product in the search results",
    "Scroll down to see the product details and reviews",
]
```

## Troubleshooting

| Symptom | Likely cause | Fix |
| --- | --- | --- |
| Agent can't find search bar | Page layout changed or slow load | Add a wait step or be more specific in the todo |
| Sort dropdown not found | Amazon UI varies by region | Update todo with exact button text for your locale |
| VLM returns incomplete data | Products not fully visible | Scroll the page or take multiple screenshots |
| `FileNotFoundError` for model config | Missing `apis/gemini.json` | Create the config file with your VLM credentials |

With this workflow you now have a reusable Amazon data extraction pattern that combines OAGI's browser automation with VLM-powered visual data extraction.